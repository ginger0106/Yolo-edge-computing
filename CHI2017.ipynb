{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI 2017\n",
    "\n",
    "浏览了ＣＨＩ２０１７的文章，主要选择了一些跟我们相近的ｓｅｓｓｉｏｎ。第一次看这个会议，总的来说，页数比较短５－１０＋，内容都十分偏重应用，并且大多有ｃａｓｅ　ｓｄｕｔｙ，实验设计或者测试中大多有人的参与，存在很多主观因素。\n",
    "\n",
    "## Video \"Smart\" Viewers\n",
    "1. Keita Higuchi, Ryo Yonetani, Yoichi Sato:\n",
    "EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines. 6536-6546\n",
    "[project](https://yonetaniryo.github.io/2017/01/16/hys-chi2017.html)\n",
    "![](hys-chi2017.png)\n",
    "主要工作是设计了一个elastic timeline：对于一个第一人称视频，如果要快速搜索发生了什么重要的事情，是比较耗时的。因此他们设计了一种弹性时间线，在非重要的时候，加速播放视频，在重点的时候正常速度播放视频。\n",
    "重要的事情定义：\n",
    "\n",
    "![](Screenshot from 2018-01-20 20-03-40.png)\n",
    "通过应用the state of art 的detection方法来识别运动、手工制作、和人。\n",
    "\n",
    "想法：这可能是实现ｒｅｍｉｎｄｅｒ的一种方式。\n",
    "记得小时候玩过一种游戏，叫做“时间，地点，人物，事件”。\n",
    "如果一个人在某处停下来，并且识别出画面中有人，在记录下时间地点或者额外的信息，生成一张图片，作为ｒｅｍｉｎｄｅｒ？\n",
    "\n",
    "**************************\n",
    "\n",
    "这个ｓｅｓｓｉｏｎ中的其他的文章都是对视频的处理：\n",
    "Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality.\n",
    "把传统的２Ｄ教学视频，变成三维的ＡＲ教学视频。\n",
    "\n",
    "Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles. \n",
    "这篇文章主要讲检测视频中的人物，并把该人物的所说的相关字幕放在该人物旁边。\n",
    "\n",
    "Responsive Action-based Video Synthesis.\n",
    "这篇文章是将视频片段变成一个可循环的序列，可以通过终端用户的要求来对视频进行合成。例如，讲现实中人的动作和视频中的动作同步。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Improving Video Communication\n",
    "1. \tKeita Suzuki, Masanori Yokoyama, Shigeo Yoshida, Takayoshi Mochizuki, Tomohiro Yamada, Takuji Narumi, Tomohiro Tanikawa, Michitaka Hirose:\n",
    "FaceShare: Mirroring with Pseudo-Smile Enriches Video Chat Communications\n",
    "\n",
    "如果在视频聊天中，检测到对面的人笑了，那么就通过面部重建方法将这边的人变成笑脸给对方回应。\n",
    "\n",
    "这个ｓｅｓｓｉｏｎ的文章都是视频聊天的应用。有些比较主观测试（Through the Looking Glass: The Effects of Feedback on Self-Awareness and Conversational Behaviour during Video Chat.）的其他文章大多跟ｇａｚｅ或者ｇｅｓｔｕｒｅ相关。\n",
    "\n",
    "## Online and On-the-go\n",
    "1. Fengpeng Yuan, Xianyi Gao, Janne Lindqvist:\n",
    "How Busy Are You?: Predicting the Interruptibility Intensity of Mobile Users.\n",
    "\n",
    "对人们收到手机通知的可被打扰性的建模和预测。收集的数据中有主观数据，例如人的情绪。\n",
    "\n",
    "想法：只是觉得也许这些概念梓涵他们也许可以参考。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
